<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 References | Summarise Tables</title>
  <meta name="description" content="Learn core commands for text pre-processing." />
  <meta name="generator" content="bookdown 0.24.3 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 References | Summarise Tables" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://ccss-rs/nlp-for-socsci" />
  
  <meta property="og:description" content="Learn core commands for text pre-processing." />
  <meta name="github-repo" content="ccss-rs/nlp-for-socsci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 References | Summarise Tables" />
  
  <meta name="twitter:description" content="Learn core commands for text pre-processing." />
  

<meta name="author" content="Remy Stewart" />


<meta name="date" content="2022-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="methodsethics.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a>Natural Language Prcoessing for the Social Sciences</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Fundamental Concepts</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#text-as-data"><i class="fa fa-check"></i><b>2.1</b> Text as Data</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#natural-language-processing"><i class="fa fa-check"></i><b>2.2</b> Natural Language Processing</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#computational-social-sciences"><i class="fa fa-check"></i><b>2.3</b> Computational Social Sciences</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#nlp-core-vocabulary"><i class="fa fa-check"></i><b>2.4</b> NLP Core Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="textproc.html"><a href="textproc.html"><i class="fa fa-check"></i><b>3</b> Text Pre-processing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="textproc.html"><a href="textproc.html#character-encoding"><i class="fa fa-check"></i><b>3.1</b> Character Encoding</a></li>
<li class="chapter" data-level="3.2" data-path="textproc.html"><a href="textproc.html#string-cleaning"><i class="fa fa-check"></i><b>3.2</b> String Cleaning</a></li>
<li class="chapter" data-level="3.3" data-path="textproc.html"><a href="textproc.html#regular-expressions"><i class="fa fa-check"></i><b>3.3</b> Regular Expressions</a></li>
<li class="chapter" data-level="3.4" data-path="textproc.html"><a href="textproc.html#lowercasing-concatenation"><i class="fa fa-check"></i><b>3.4</b> Lowercasing &amp; Concatenation</a></li>
<li class="chapter" data-level="3.5" data-path="textproc.html"><a href="textproc.html#tokenization"><i class="fa fa-check"></i><b>3.5</b> Tokenization</a></li>
<li class="chapter" data-level="3.6" data-path="textproc.html"><a href="textproc.html#optional-method-dependent-pre-processing-steps"><i class="fa fa-check"></i><b>3.6</b> Optional Method-Dependent Pre-processing Steps</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="textproc.html"><a href="textproc.html#stopwords"><i class="fa fa-check"></i><b>3.6.1</b> Stopwords</a></li>
<li class="chapter" data-level="3.6.2" data-path="textproc.html"><a href="textproc.html#stemming"><i class="fa fa-check"></i><b>3.6.2</b> Stemming</a></li>
<li class="chapter" data-level="3.6.3" data-path="textproc.html"><a href="textproc.html#parts-of-speech"><i class="fa fa-check"></i><b>3.6.3</b> Parts-of-Speech</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dictionary.html"><a href="dictionary.html"><i class="fa fa-check"></i><b>4</b> Dictionaries &amp; Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dictionary.html"><a href="dictionary.html#types-of-dictionaries"><i class="fa fa-check"></i><b>4.1</b> Types of Dictionaries</a></li>
<li class="chapter" data-level="4.2" data-path="dictionary.html"><a href="dictionary.html#sentiment-analysis"><i class="fa fa-check"></i><b>4.2</b> Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dictionary.html"><a href="dictionary.html#vader"><i class="fa fa-check"></i><b>4.2.1</b> VADER</a></li>
<li class="chapter" data-level="4.2.2" data-path="dictionary.html"><a href="dictionary.html#string-sentiment"><i class="fa fa-check"></i><b>4.2.2</b> String Sentiment</a></li>
<li class="chapter" data-level="4.2.3" data-path="dictionary.html"><a href="dictionary.html#rnyc-sentiment"><i class="fa fa-check"></i><b>4.2.3</b> r/nyc Sentiment</a></li>
<li class="chapter" data-level="4.2.4" data-path="dictionary.html"><a href="dictionary.html#sentiment-score"><i class="fa fa-check"></i><b>4.2.4</b> Sentiment &amp; Score</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dictionary.html"><a href="dictionary.html#beyond-dictionaries"><i class="fa fa-check"></i><b>4.3</b> Beyond Dictionaries</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>5</b> Machine Learning &amp; Topic Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ml.html"><a href="ml.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>5.1</b> Supervised vs. Unsupervised Learning</a></li>
<li class="chapter" data-level="5.2" data-path="ml.html"><a href="ml.html#topic-models"><i class="fa fa-check"></i><b>5.2</b> Topic Models</a></li>
<li class="chapter" data-level="5.3" data-path="ml.html"><a href="ml.html#structural-topic-models"><i class="fa fa-check"></i><b>5.3</b> Structural Topic Models</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ml.html"><a href="ml.html#pre-processing"><i class="fa fa-check"></i><b>5.3.1</b> Pre-processing</a></li>
<li class="chapter" data-level="5.3.2" data-path="ml.html"><a href="ml.html#fitting-the-model"><i class="fa fa-check"></i><b>5.3.2</b> Fitting the Model</a></li>
<li class="chapter" data-level="5.3.3" data-path="ml.html"><a href="ml.html#variation-by-comment-score"><i class="fa fa-check"></i><b>5.3.3</b> Variation by Comment Score</a></li>
<li class="chapter" data-level="5.3.4" data-path="ml.html"><a href="ml.html#extending-machine-learning"><i class="fa fa-check"></i><b>5.3.4</b> Extending Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methodsethics.html"><a href="methodsethics.html"><i class="fa fa-check"></i><b>6</b> Further Applications &amp; Ethical Considerations</a>
<ul>
<li class="chapter" data-level="6.1" data-path="methodsethics.html"><a href="methodsethics.html#embeddings"><i class="fa fa-check"></i><b>6.1</b> Embeddings</a></li>
<li class="chapter" data-level="6.2" data-path="methodsethics.html"><a href="methodsethics.html#supervised-classification"><i class="fa fa-check"></i><b>6.2</b> Supervised Classification</a></li>
<li class="chapter" data-level="6.3" data-path="methodsethics.html"><a href="methodsethics.html#networks"><i class="fa fa-check"></i><b>6.3</b> Networks</a></li>
<li class="chapter" data-level="6.4" data-path="methodsethics.html"><a href="methodsethics.html#causality"><i class="fa fa-check"></i><b>6.4</b> Causality</a></li>
<li class="chapter" data-level="6.5" data-path="methodsethics.html"><a href="methodsethics.html#ethics-of-nlp"><i class="fa fa-check"></i><b>6.5</b> Ethics of NLP</a></li>
<li class="chapter" data-level="6.6" data-path="methodsethics.html"><a href="methodsethics.html#future-directions"><i class="fa fa-check"></i><b>6.6</b> Future Directions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a>
<ul>
<li class="chapter" data-level="7.1" data-path="references.html"><a href="references.html#chapter-1--introduction"><i class="fa fa-check"></i><b>7.1</b> Chapter 1- Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="references.html"><a href="references.html#data-and-the-information-age"><i class="fa fa-check"></i><b>7.1.1</b> Data and the Information Age</a></li>
<li class="chapter" data-level="7.1.2" data-path="references.html"><a href="references.html#css-and-nlp"><i class="fa fa-check"></i><b>7.1.2</b> CSS and NLP</a></li>
<li class="chapter" data-level="7.1.3" data-path="references.html"><a href="references.html#nlp-resources-specific-to-r-applications"><i class="fa fa-check"></i><b>7.1.3</b> NLP Resources Specific to R Applications</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="references.html"><a href="references.html#chapter-2--text-preprocessing"><i class="fa fa-check"></i><b>7.2</b> Chapter 2- Text Preprocessing</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="references.html"><a href="references.html#text-preprocessing"><i class="fa fa-check"></i><b>7.2.1</b> Text Preprocessing</a></li>
<li class="chapter" data-level="7.2.2" data-path="references.html"><a href="references.html#stemming-stopwords-and-parts-of-speech"><i class="fa fa-check"></i><b>7.2.2</b> Stemming, Stopwords, and Parts of Speech</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="references.html"><a href="references.html#chapter-3-dictionaries-sentiment-analysis"><i class="fa fa-check"></i><b>7.3</b> Chapter 3 – Dictionaries &amp; Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="references.html"><a href="references.html#counts-dictionary-based-studies"><i class="fa fa-check"></i><b>7.3.1</b> Counts &amp; Dictionary Based Studies</a></li>
<li class="chapter" data-level="7.3.2" data-path="references.html"><a href="references.html#liwc"><i class="fa fa-check"></i><b>7.3.2</b> LIWC</a></li>
<li class="chapter" data-level="7.3.3" data-path="references.html"><a href="references.html#sentiment-analysis-1"><i class="fa fa-check"></i><b>7.3.3</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="7.3.4" data-path="references.html"><a href="references.html#vader-1"><i class="fa fa-check"></i><b>7.3.4</b> VADER</a></li>
<li class="chapter" data-level="7.3.5" data-path="references.html"><a href="references.html#alternative-sentiment-analysis-approaches"><i class="fa fa-check"></i><b>7.3.5</b> Alternative Sentiment Analysis Approaches</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="references.html"><a href="references.html#chapter-4--machine-learning-topic-models"><i class="fa fa-check"></i><b>7.4</b> Chapter 4- Machine Learning &amp; Topic Models</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="references.html"><a href="references.html#machine-learning-for-social-science-annual-reviews"><i class="fa fa-check"></i><b>7.4.1</b> Machine Learning for Social Science Annual Reviews</a></li>
<li class="chapter" data-level="7.4.2" data-path="references.html"><a href="references.html#topic-model-papers"><i class="fa fa-check"></i><b>7.4.2</b> Topic Model Papers</a></li>
<li class="chapter" data-level="7.4.3" data-path="references.html"><a href="references.html#structural-topic-models-author-papers"><i class="fa fa-check"></i><b>7.4.3</b> Structural Topic Models Author Papers</a></li>
<li class="chapter" data-level="7.4.4" data-path="references.html"><a href="references.html#css-research-using-topic-models"><i class="fa fa-check"></i><b>7.4.4</b> CSS Research Using Topic Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="references.html"><a href="references.html#chapter-5--further-applications-ethics"><i class="fa fa-check"></i><b>7.5</b> Chapter 5- Further Applications &amp; Ethics</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="references.html"><a href="references.html#further-applications"><i class="fa fa-check"></i><b>7.5.1</b> Further Applications</a></li>
<li class="chapter" data-level="7.5.2" data-path="references.html"><a href="references.html#ethics-within-nlp"><i class="fa fa-check"></i><b>7.5.2</b> Ethics within NLP</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a>Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Summarise Tables</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> References</h1>
<p>This reference list is divided by each of the user guide’s chapters along with subheaders for the connecting theme between each group of citations. I decided to order each cluster descending by year since NLP is a rapidly growing discipline and starting with older works will likely aid reader’s understanding of newer innovations. The featured references undeniably reflect my own disciplinary training biases in sociology &amp; information science, but I think social scientists outside of either of those specific disciplines can still gain much from the included papers.</p>
<p>I purposely tried to highlight Cornell scholars and researchers throughout the sections. There’s no way I could include the sheer variety of research without this list becoming massive, so consider this to be a further reading “launch pad” aligned with the introduced topics in the user guide that you can then expand on further within your own literature reviews.</p>
<div id="chapter-1--introduction" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Chapter 1- Introduction</h2>
<div id="data-and-the-information-age" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Data and the Information Age</h3>
<ul>
<li>Golder, Scott and Michael Macy. 2014. “Digital Footprints: Opportunities and Challenges for Online Social Research.” <em>Annual Review of Sociology</em> 40: 129-152.</li>
<li>Salganik, Matthew. 2018. <em>Bit by Bit: Social Research in the Digital Age.</em> Princeton, NJ: Princeton University Press.</li>
<li>Brady, Henry E. 2019. “The Challenges of Big Data and Data Science.” <em>Annual Review of Political Science</em> 22: 297-323.</li>
<li>Hargittai, Eszter. 2020. “Potential Biases in Big Data: Omitted Voices on Social Media.” <em>Social Science Computer Review</em> 38(1): 10-24.</li>
</ul>
</div>
<div id="css-and-nlp" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> CSS and NLP</h3>
<ul>
<li>DiMaggio, Paul. 2015. “Adapting Computational Text Analysis to Social Science (and Vice Versa).” <em>Big Data &amp; Society</em> 2(2): 1-5.</li>
<li>Evans, James A. and Pedro Aceves. 2016. “Machine Translation: Mining Text for Social Theory.” <em>Annual Review of Sociology</em> 42: 21-50.</li>
<li>Nelson, Laura K. 2017. “Computational Grounded Theory: A Methodological Framework.” <em>Sociological Methods &amp; Research</em> 49(1): 3-42.</li>
<li>Wallach, Hanna. 2018. “Computational Social Science ≠ Computer Science + Social Data.” <em>Communications of the ACM</em> 61(3): 42-44.</li>
<li>Lazer et al. 2020. “Computational Social Science: Obstacles and Opportunities.” <em>Science</em> 369(6507): 1060-1062.</li>
<li>Grimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2021. <em>Text as Data: A New Framework for Machine Learning and the Social Sciences.</em> Princeton, NJ: Princeton University Press.</li>
</ul>
</div>
<div id="nlp-resources-specific-to-r-applications" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> NLP Resources Specific to R Applications</h3>
<ul>
<li>Silge, Julia, and David Robinson. 2017. <em>Text Mining with R: A Tidy Approach.</em> Newton, MA: O’Reilly Media</li>
<li>Jockers, Matthew L. and Rosamond Thalken. 2020. <em>Text Analysis with R</em>. New York, NY: Springer.</li>
<li>Hvitfeldt, Emil and Julia Silge. 2021. <em>Supervised Machine Learning for Text Analysis in R.</em> Boca Raton, Florida: CRC Press.</li>
</ul>
</div>
</div>
<div id="chapter-2--text-preprocessing" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Chapter 2- Text Preprocessing</h2>
<div id="text-preprocessing" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Text Preprocessing</h3>
<ul>
<li>Helpful blog post on encodings- <a href="https://kunststube.net/encoding/" class="uri">https://kunststube.net/encoding/</a></li>
<li>Uysal, A. K., and Gunal, S. 2014. “The Impact of Preprocessing on Text Classification.” <em>Information Processing &amp; Management</em> 50(1), 104-112.</li>
<li>Denny, M. J., and Spirling, A. 2018. “Text Preprocessing For Unsupervised Learning: Why It Matters, When It Misleads, And What To Do About It.” <em>Political Analysis</em> 26(2): 168–189.</li>
<li>Hickman, Louis, Stuti Thapa, … et al. 2020. “Text Preprocessing for Text Mining in Organizational Research: Review and Recommendations.” <em>Organizational Research Methods</em>: 1-33.</li>
<li>Great website to learn regexes- <a href="https://www.regular-expressions.info/" class="uri">https://www.regular-expressions.info/</a></li>
</ul>
</div>
<div id="stemming-stopwords-and-parts-of-speech" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Stemming, Stopwords, and Parts of Speech</h3>
<ul>
<li>Derczynski, Leon, Alan Ritter, Sam Clark, and Kalina Bontcheva. 2013. “Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data.” <em>Proceedings of Recent Advances in Natural Language Processing</em>: 198-206.</li>
<li>Tsuboi, Yuta. 2014. “Neural Networks Leverage Corpus-wide Information for Part-of-Speech Tagging.” <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</em>: 938-950.</li>
<li>Schofield, A., and Mimno, D. 2016. “Comparing Apples to Apple: The Effects of Stemmers on Topic Models.” <em>TACL</em> 4(2): 287–300.</li>
<li>Singh, Jasmeet and Vishal Gupta. 2017. “A Systematic Review of Text Stemming Techniques.” <em>Artificial Intelligence Review</em> 48: 157-217.</li>
<li>Schofield, Alexandra, Måns Magnusson, and David Mimno. 2017. “Pulling Out the Stops: Rethinking Stopword Removal for Topic Models.” <em>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</em>: 432-436.</li>
</ul>
</div>
</div>
<div id="chapter-3-dictionaries-sentiment-analysis" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Chapter 3 – Dictionaries &amp; Sentiment Analysis</h2>
<div id="counts-dictionary-based-studies" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Counts &amp; Dictionary Based Studies</h3>
<ul>
<li>Monroe, Burt, Michael Colaresi, and Kevin Quinn. 2008. “Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict.” <em>Political Analysis</em> 16(4): 372-403.</li>
<li>Loughran, Tim and Bill McDonald. 2011. “When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks” <em>The Journal of Finance</em> 66(1): 35-65.</li>
<li>Sap, Maarten, Marcella Cindy Prasetio, Ari Holtzman, Hannah Rashkin, and Yejin Choi. 2017. “Connotation Frames of Power and Agency in Modern Films.” <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>: 2329-2334.</li>
<li>Antoniak, Maria and David Mimno. 2021. “Bad Seeds: Evaluating Lexical Methods for Bias Measurement.” <em>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</em>: 1889-1904.</li>
</ul>
</div>
<div id="liwc" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> LIWC</h3>
<ul>
<li>Tausczik, Yla R., and James W. Pennebaker. 2010. ”The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods.” <em>Journal of Language and Social Psychology</em> 29(1): 24-54.</li>
<li>Bulkeley, Kelly and Mark Graves. 2018. “Using the LIWC program to study dreams.” <em>Dreaming</em> 28(1): 43–58.</li>
<li>Sergent, Kayla and Alexander D. Stajkovic. 2020. “Women’s Leadership is Associated with Fewer Deaths During the COVID-19 Crisis: Quantitative and Qualitative Analyses of United States Governors.” <em>Journal of Applied Psychology</em> 105(8): 771-783.</li>
<li>Yin, Dezhi, Samuel D. Bond, and Han Zhang. 2021. “Anxious or Angry? Effects of Discrete Emotions on the Perceived Helpfulness of Online Reviews.” <em>MIS Quarterly</em> 38(2): 539-560.</li>
</ul>
</div>
<div id="sentiment-analysis-1" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Sentiment Analysis</h3>
<ul>
<li>Pang, Bo, and Lillian Lee. 2008. “Opinion Mining and Sentiment Analysis.” <em>Foundations and Trends in Information Retrieval</em> 2(1–2): 1–135.</li>
<li>Bao, Yanwei, Changqin Qian, Lijuan Wang, and Fuji Ren. 2014. “The Role of Pre-Processing in Twitter Sentiment Analysis.” <em>International Conference on Intelligent Computing</em>: 615-624.</li>
<li>Chauhan, Priyavrat, Nonita Sharma, and Geeta Sikka. 2021. “The Emergence of Social Media Data and Sentiment Analysis in Election Prediction.” <em>Journal of Ambient Intelligence and Humanized Computing</em> 12: 2601-2627.</li>
</ul>
</div>
<div id="vader-1" class="section level3" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> VADER</h3>
<ul>
<li>O’Connor, Brendan, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. “From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series.” <em>Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM)</em>: 122-129.</li>
<li>Hutto, C.J. and Eric Gilbert. 2014. “VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.” <em>Proceedings of the Eighth International AAAI Conference on Weblogs and Social Media</em>: 216-225.</li>
<li>Kim, Young Bin, Jun Gi Kim, … et al. 2016. “Predicting Fluctuations in Cryptocurrency Transactions Based on User Comments and Replies.” <em>PLOS ONE</em> 11(8): 1-17.</li>
<li>Kumar, Srijan, William L. Hamilton, Jure Leskovec, and Dan Jurafsky. 2018. “Community Interaction and Conflict on the Web” <em>WWW</em>: 933-943.</li>
</ul>
</div>
<div id="alternative-sentiment-analysis-approaches" class="section level3" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Alternative Sentiment Analysis Approaches</h3>
<ul>
<li>Soleymani, Mohammad, David Garcia, … et al. 2017. “A Survey of Multimodal Sentiment Analysis.” <em>Image and Vision Computing</em> 65: 3-14.</li>
<li>Hemmatian, Fatemeh and Mohammad Karim Sohrabi. 2019. “A Survey on Classification Techniques for Opinion Mining and Sentiment Analysis.” <em>Artificial Intelligence Review</em> 52: 1495-1545.</li>
<li>Yadav, Ashima and Dinesh Kumar Vishwakarma. 2019. “Sentiment Analysis Using Deep Learning Architectures: A Review.” <em>Artificial Intelligence Review</em> 53: 4335-4385.</li>
</ul>
</div>
</div>
<div id="chapter-4--machine-learning-topic-models" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Chapter 4- Machine Learning &amp; Topic Models</h2>
<div id="machine-learning-for-social-science-annual-reviews" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Machine Learning for Social Science Annual Reviews</h3>
<ul>
<li>Molina, Mario and Filiz Garip. 2019. “Machine Learning for Sociology.” <em>Annual Review of Sociology</em> 45: 27-45.</li>
<li>Athey, Susan and Guido W. Imbens. 2019. “Machine Learning Methods That Economists Should Know About.” <em>Annual Review of Economics</em> 11: 685-725.</li>
<li>Orrù, Graziella, Merylin Monaro, … et al. 2020. “Machine Learning in Psychometrics and Psychological Research.” <em>Frontiers in Psychology</em> 10(2970): 1-10.</li>
<li>Grimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2021. “Machine Learning for Social Science: An Agnostic Approach.” <em>Annual Review of Political Science</em> 24: 395-419.</li>
</ul>
</div>
<div id="topic-model-papers" class="section level3" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Topic Model Papers</h3>
<ul>
<li>Chang, Jonathan, Jordan Boyd-Graber, Sean Gerrish, Chong Wang, and David M. Blei. 2009. “Reading Tea Leaves: How Humans Interpret Topic Models.” <em>Advances in Neural Information Processing Systems</em> 22: 1-9.</li>
<li>Blei, David. 2012. “Probabilistic Topic Models.” <em>Communications of the ACM</em> 55 (4): 77-84.</li>
<li>Mohr, John, and Petko Bogdanov. 2013. “Introduction—Topic Models: What They Are and Why They Matter.” <em>Poetics</em> 41 (6): 545–69.</li>
<li>Baumer, Erin P.S., David Mimno, Shion Guha, Emily Quan, and Geri K. Gay. 2017. “Comparing Grounded Theory and Topic Modeling: Extreme Divergence or Unlikely Convergence?” <em>Journal of the Association for Information Science and Technology</em> 68(6): 1397-1410.</li>
</ul>
</div>
<div id="structural-topic-models-author-papers" class="section level3" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Structural Topic Models Author Papers</h3>
<ul>
<li>Check out the structural topic model website for an extensive list of studies that have used STMs - <a href="https://www.structuraltopicmodel.com/" class="uri">https://www.structuraltopicmodel.com/</a></li>
<li>Roberts, Stewart, Tingley, Lucas, Leder-Luis, Gadarian, Albertson, and Rand. 2014. “Structural Topic Models for Open-Ended Survey Responses.” <em>American Journal of Political Science</em> 58(4): 1064-1082.</li>
<li>Roberts, Margaret, Brandon Stewart, and Dustin Tingley. 2019. “stm: A Package for Structural Topic Models.” <em>Journal of Statistical Software</em> 91(2):1-40.</li>
</ul>
</div>
<div id="css-research-using-topic-models" class="section level3" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> CSS Research Using Topic Models</h3>
<ul>
<li>DiMaggio, Paul, Manish Nag, and David Blei. 2013. “Exploiting Affinities between Topic Modeling and the Sociological Perspective on Culture: Application to Newspaper Coverage of U.S. Government Arts Funding.” <em>Poetics</em> 41(6): 570-606.</li>
<li>Barberá, Pablo, Andreu Casas, Jonathan Nagler, Patrick J. Egan, Richard Bonneau, John T. Jost, and Joshua A. Tucker. 2019. “Who Leads? Who Follows? Measuring Issue Attention and Agenda Setting by Legislators and the Mass Public Using Social Media Data.” <em>American Political Science Review</em> 113(4): 883-901.</li>
<li>Karell, Daniel and Michael Freedman. 2019. “Rhetorics of Radicalism.” <em>American Sociological Review</em> 84(4): 726-753.<br />
</li>
<li>Kennedy, I., C. Hess, A. Paullada, and S. Chasins. 2021. “Racialized Discourse in Seattle Rental Ad Text.” <em>Social Forces</em> 99(4): 1432–1456.</li>
</ul>
</div>
</div>
<div id="chapter-5--further-applications-ethics" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Chapter 5- Further Applications &amp; Ethics</h2>
<div id="further-applications" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Further Applications</h3>
<div id="word-embeddings" class="section level4" number="7.5.1.1">
<h4><span class="header-section-number">7.5.1.1</span> Word Embeddings</h4>
<ul>
<li>Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” <em>Proceedings of Workshop at ICLR</em>: 1-22.</li>
<li>Levy, Omer and Yoav Goldberg. 2014. “Neural Word Embedding as Implicit Matrix Factorization.” <em>Advances in Neural Information Processing Systems</em> 27: 1-9.</li>
<li>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. “Word Embeddings Quantify 100 years of Gender and Ethnic Stereotypes.” <em>Proceedings of the National Academy of Sciences</em> 115(16): E3635–E3644.</li>
<li>Kozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” <em>American Sociological Review</em> 84(5): 905–949.</li>
<li>Arseniev-Koehler, Alina and Jacob G. Foster. 2020. “Machine Learning as a Model for Cultural Learning: Teaching an Algorithm what it Means to be Fat.” Preprint, SocArXiv.</li>
</ul>
</div>
<div id="supervised-nlp-classification-applied-studies" class="section level4" number="7.5.1.2">
<h4><span class="header-section-number">7.5.1.2</span> Supervised NLP Classification Applied Studies</h4>
<ul>
<li>Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, and Lillian Lee. 2016. “Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-Faith Online Discussions,” <em>WWW</em>: 613–624.</li>
<li>Davidson, Thomas, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. “Automated Hate Speech Detection and the Problem of Offensive Language.” <em>Proceedings of the 11th International Conference on Web and Social Media (ICWSM)</em>: 512–515.</li>
<li>Zhang, Justine, Jonathan P. Chang, Christian Danescu-Niculescu-Mizil, Lucas Dixon, Nithum Thain, Yiqing Hua, and Dario Taraborelli. 2018. “Conversations Gone Awry: Detecting Early Signs of Conversational Failure.” <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</em> 1: 1350-1361.</li>
<li>Barberá, Pablo, Amber E. Boydstun, Suzanna Linn, Ryan McMahon, and Jonathan Nagler. 2020. “Automated Text Classification of News Articles: A Practical Guide.” <em>Political Analysis</em>: 1–24</li>
</ul>
</div>
<div id="networks-1" class="section level4" number="7.5.1.3">
<h4><span class="header-section-number">7.5.1.3</span> Networks</h4>
<ul>
<li>Gonzales-Bailon, Sanda, Andreas Kaltenbrunner, and Rafael E Banchs. 2010. “The Structure of Political Discussion Networks: A Model for the Analysis of Online Deliberation.” <em>Journal of Information Technology</em> 25: 230-243.</li>
<li>Rule, Alix, Jean-Phillippe Cointet, and Peter S. Bearman. 2015. “Lexical Shifts, Substantive Changes, and Continuity in State of the Union Discourse, 1790-2014.” <em>PNAS</em> 112(35): 10837-10844.</li>
<li>Bail, Christopher A. 2016. “Combining Natural Language Processing and Network Analysis to Examine How Advocacy Organizations Stimulate Conversation on Social Media.” <em>Proceedings of the National Academy of Sciences</em> 113(42): 11823-28.</li>
<li>Vega, Davide and Matteo Magnani. 2018. “Foundations of Temporal Text Networks.” <em>Applied Network Science</em> 3(25): 1-26.</li>
</ul>
</div>
<div id="casual-inference" class="section level4" number="7.5.1.4">
<h4><span class="header-section-number">7.5.1.4</span> Casual Inference</h4>
<ul>
<li>Great GitHub repository of text &amp; causality papers across disciplines-<a href="https://github.com/causaltext/causal-text-papers" class="uri">https://github.com/causaltext/causal-text-papers</a></li>
<li>Bryan, Christopher J., Gregory M. Walton, Todd Rogers, and Carol S. Dweck. 2011. “Motivating Voter Turnout by Invoking the Self.” <em>PNAS</em> 108(31): 12653-12656.</li>
<li>Feder et al. 2021. “Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond.” arXiv preprint arXiv: 2109.00725.</li>
<li>Pryzant, Reid, Dallas Card, Dan Jurafsky, Victor Veitch, and Dhanya Sridhar. 2021. “Causal Effects of Linguistic Properties.” <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>: 4095-4109.</li>
</ul>
</div>
</div>
<div id="ethics-within-nlp" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Ethics within NLP</h3>
<p>Here’s a fantastic fairness within NLP Github repo from the UCLA NLP group that the following citations also draws from- <a href="https://github.com/uclanlp/awesome-fairness-papers" class="uri">https://github.com/uclanlp/awesome-fairness-papers</a></p>
<div id="broad-social-implications-of-nlp" class="section level4" number="7.5.2.1">
<h4><span class="header-section-number">7.5.2.1</span> Broad Social Implications of NLP</h4>
<ul>
<li>Hovy, Dirk and Shannon L. Spruit. 2016. “The Social Impact of Natural Language Processing.” <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</em> 2: 591-598.</li>
<li>Blodgett, Su Lin, Solon Barocas, Hal Daum III, and Hanna Wallach. 2020. “Language (Technology) is Power: A Critical Survey of ‘Bias’ in NLP.” <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5454-5476.</li>
<li>Leins, Kobi, Jey Han Lau, and Timothy Baldwin. 2020. “Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?” <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 2908-2913.</li>
</ul>
</div>
<div id="nlps-perpetuation-of-bias-and-unethical-practices" class="section level4" number="7.5.2.2">
<h4><span class="header-section-number">7.5.2.2</span> NLP’s Perpetuation of Bias and Unethical Practices</h4>
<ul>
<li>Sap, Maarten, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. 2019. “The Risk of Racial Bias in Hate Speech Detection.” <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 1668-1678.</li>
<li>Gonen, Hila and Yoav Goldberg. 2019. “Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But Do Not Remove Them.” <em>Proceedings of NAACL-HLT</em>: 609-614.</li>
<li>Hutchinson, Ben, Vinodkumar Prabhakaran, … et al. 2020. “Social Biases in NLP Models as Barriers for Persons with Disabilities.” <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5491-5501.</li>
<li>Shmueli, Boaz, Jan Fell, Soumya Ray, and Lun-Wei Ku. 2021. “Beyond Fair Pay: Ethical Implications of NLP Crowdsourcing” <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>: 3758–3769</li>
<li>Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Smitchell. 2021. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>: 610-623.</li>
</ul>
</div>
<div id="nlps-revealing-of-bias-and-unethical-practices" class="section level4" number="7.5.2.3">
<h4><span class="header-section-number">7.5.2.3</span> NLP’s Revealing of Bias and Unethical Practices</h4>
<ul>
<li>Voigt, Rob, Nicholas P Camp, … et al. 2017. “Language from Police Body Camera Footage Shows Racial Disparities in Officer Respect.” <em>PNAS</em> 114(25): 6521-6526.</li>
<li>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. “Word embeddings quantify 100 years of gender and ethnic stereotypes.” <em>Proceedings of the National Academy of Sciences 115</em> (16): E3635–E3644.</li>
<li>Merullo, Jack, Luke Yeh, … et al. 2019. “Investigating Sports Commentator Bias Within a Large Corpus of American Football Broadcasts.” <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</em>: 6355-6361.</li>
<li>Sap, Maarten, Saadia Gabriel, … et al. 2020. “Social Bias Frames: Reasoning about Social and Power Implications of Language.” <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5477-5490.</li>
</ul>
</div>
<div id="participant-privacy-consent-and-agency" class="section level4" number="7.5.2.4">
<h4><span class="header-section-number">7.5.2.4</span> Participant Privacy, Consent, and Agency</h4>
<ul>
<li>Nissenbaum, Helen. 2004. “Privacy as Contextual Integrity.” <em>Washington Law Review</em> 79(1): 101-139.</li>
<li>Williams, Matthew L., Pete Burnap, and Luke Sloan. 2017. “Towards an Ethical Framework for Publishing Twitter Data in Social Research: Taking into Account Users’ Views, Online Context and Algorithmic Estimation.” <em>Sociology</em> 51(6): 1149-1168.</li>
<li>Susser, Daniel, Beate Roessler, and Helen Nissenbaum. 2019. “Technology, Autonomy, and Manipulation.” <em>Internet Policy Review</em> 8(2): 1-22.</li>
<li>Caselli, Tommaso, Roberto Cibin, … et al. 2021. “Guiding Principles for Participatory Design-Inspired Natural Language Processing.” <em>Proceedings of the 1st Workshop on NLP for Positive Impact</em>: 27-35.</li>
</ul>
</div>
<div id="incorporating-ethical-practices-within-nlp" class="section level4" number="7.5.2.5">
<h4><span class="header-section-number">7.5.2.5</span> Incorporating Ethical Practices Within NLP</h4>
<ul>
<li>Bender, Emily M. and Batya Friedman. 2018. “Data Statements for Natural Language Processing: Towards Mitigating System Bias and Enabling Better Science.” <em>Transactions of the Association for Computational Linguistics</em> 6: 587-604.</li>
<li>Jurgens, David, Eshwar Chandrasekharan, and Libby Hemphill. 2019. “A Just and Comprehensive Strategy for Using NLP to Address Online Abuse.” <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 3658-3666.</li>
<li>Sun, Tony, Andrew Gaut… et al. 2019. “Mitigating Gender Bias in Natural Language Processing: Literature Review.” <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 1630-1640.</li>
<li>Havens, Lucy, Melissa Terras, Benjamin Bach, and Beatrice Alex. 2020. “Situated Data, Situated Systems: A Methodology to Engage with Power Relations in Natural Language Processing Research.” <em>Proceedings of the Second Workshop on Gender Bias in Natural Language Processing</em>: 107-124.</li>
</ul>

<p>In this demo, we’ll be performing exploratory analysis on the expressed emotional
sentiment of r/nyc users as embedded within their comment text. We will use readr,
dplylr, and stringr once again as these packages are core libraries
across NLP use cases. We’re also including the <strong>vader</strong> package which wraps the original
VADER sentiment analyser written in Python for R as well as <strong>ggplot</strong> for simple
data visualizations. Let’s load them all in along with our r/nyc comment data set as follows:</p>
<p>library(readr)
library(dplyr)
library(stringr)
library(vader)
library(ggplot2)</p>
<p>nyc &lt;- read_csv(“nyc_reddit.csv”)</p>
<p>get_vader(“As someone who always depended on cars before, I LOVE the subway! &lt;3”)</p>
<p>get_vader(“The subway is very helpful, but I’m not a fan of the rats.”)</p>
<p>get_vader(“I hate how delayed the subway always is… being late for work sucks. :(”)</p>
<p>nyc_sentiment &lt;- vader_df(nyc$body)
nyc_sentiment</p>
<p>nyc_sentiment &lt;- read_csv(‘nyc_sentiment.csv’)</p>
<p>top_pos &lt;- nyc_sentiment %&gt;%
top_n(5, compound)
top_pos$body</p>
<p>top_neg &lt;- nyc_sentiment %&gt;%
top_n(-5, compound)
top_neg</p>
<p>nyc_full &lt;- merge(nyc, nyc_sentiment, by = “body”)</p>
<p>To prepare for this analysis, I’ll first have to join my separate data frames of
both the baseline Reddit data and the VADER scores by comment. We’ll then consider
comments with a positive rating score of 20 through ggplot scatter plots.</p>
<p>ggplot(nyc_full[which(nyc_full$score&gt;20),], aes(x=compound, y=score)) + geom_point()</p>
<p>Let’s look at the equivalent for sentiment among posts that received a negative score.</p>
<p>ggplot(nyc_full[which(nyc_full$score&lt;0),], aes(x=compound, y=score)) + geom_point()</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methodsethics.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-references.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
