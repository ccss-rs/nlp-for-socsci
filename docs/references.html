<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 References | Summarise Tables</title>
  <meta name="description" content="Learn core commands for text pre-processing." />
  <meta name="generator" content="bookdown 0.24.3 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 References | Summarise Tables" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://ccss-rs/nlp-for-socsci" />
  
  <meta property="og:description" content="Learn core commands for text pre-processing." />
  <meta name="github-repo" content="ccss-rs/nlp-for-socsci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 References | Summarise Tables" />
  
  <meta name="twitter:description" content="Learn core commands for text pre-processing." />
  

<meta name="author" content="Remy Stewart" />


<meta name="date" content="2022-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="methodsethics.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a>Natural Language Prcoessing for the Social Sciences</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Fundamental Concepts</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#text-as-data"><i class="fa fa-check"></i><b>2.1</b> Text as Data</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#natural-language-processing"><i class="fa fa-check"></i><b>2.2</b> Natural Language Processing</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#computational-social-sciences"><i class="fa fa-check"></i><b>2.3</b> Computational Social Sciences</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#nlp-core-vocabulary"><i class="fa fa-check"></i><b>2.4</b> NLP Core Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="textproc.html"><a href="textproc.html"><i class="fa fa-check"></i><b>3</b> Text Pre-processing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="textproc.html"><a href="textproc.html#character-encoding"><i class="fa fa-check"></i><b>3.1</b> Character Encoding</a></li>
<li class="chapter" data-level="3.2" data-path="textproc.html"><a href="textproc.html#string-cleaning"><i class="fa fa-check"></i><b>3.2</b> String Cleaning</a></li>
<li class="chapter" data-level="3.3" data-path="textproc.html"><a href="textproc.html#regular-expressions"><i class="fa fa-check"></i><b>3.3</b> Regular Expressions</a></li>
<li class="chapter" data-level="3.4" data-path="textproc.html"><a href="textproc.html#lowercasing-concatenation"><i class="fa fa-check"></i><b>3.4</b> Lowercasing &amp; Concatenation</a></li>
<li class="chapter" data-level="3.5" data-path="textproc.html"><a href="textproc.html#tokenization"><i class="fa fa-check"></i><b>3.5</b> Tokenization</a></li>
<li class="chapter" data-level="3.6" data-path="textproc.html"><a href="textproc.html#optional-method-dependent-pre-processing-steps"><i class="fa fa-check"></i><b>3.6</b> Optional Method-Dependent Pre-processing Steps</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="textproc.html"><a href="textproc.html#stopwords"><i class="fa fa-check"></i><b>3.6.1</b> Stopwords</a></li>
<li class="chapter" data-level="3.6.2" data-path="textproc.html"><a href="textproc.html#stemming"><i class="fa fa-check"></i><b>3.6.2</b> Stemming</a></li>
<li class="chapter" data-level="3.6.3" data-path="textproc.html"><a href="textproc.html#parts-of-speech"><i class="fa fa-check"></i><b>3.6.3</b> Parts-of-Speech</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dictionary.html"><a href="dictionary.html"><i class="fa fa-check"></i><b>4</b> Dictionaries &amp; Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dictionary.html"><a href="dictionary.html#types-of-dictionaries"><i class="fa fa-check"></i><b>4.1</b> Types of Dictionaries</a></li>
<li class="chapter" data-level="4.2" data-path="dictionary.html"><a href="dictionary.html#sentiment-analysis"><i class="fa fa-check"></i><b>4.2</b> Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dictionary.html"><a href="dictionary.html#vader"><i class="fa fa-check"></i><b>4.2.1</b> VADER</a></li>
<li class="chapter" data-level="4.2.2" data-path="dictionary.html"><a href="dictionary.html#string-sentiment"><i class="fa fa-check"></i><b>4.2.2</b> String Sentiment</a></li>
<li class="chapter" data-level="4.2.3" data-path="dictionary.html"><a href="dictionary.html#rnyc-sentiment"><i class="fa fa-check"></i><b>4.2.3</b> r/nyc Sentiment</a></li>
<li class="chapter" data-level="4.2.4" data-path="dictionary.html"><a href="dictionary.html#sentiment-score"><i class="fa fa-check"></i><b>4.2.4</b> Sentiment &amp; Score</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dictionary.html"><a href="dictionary.html#beyond-dictionaries"><i class="fa fa-check"></i><b>4.3</b> Beyond Dictionaries</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>5</b> Machine Learning &amp; Topic Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ml.html"><a href="ml.html#supervised-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>5.1</b> Supervised vs.Â Unsupervised Learning</a></li>
<li class="chapter" data-level="5.2" data-path="ml.html"><a href="ml.html#topic-models"><i class="fa fa-check"></i><b>5.2</b> Topic Models</a></li>
<li class="chapter" data-level="5.3" data-path="ml.html"><a href="ml.html#structural-topic-models"><i class="fa fa-check"></i><b>5.3</b> Structural Topic Models</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ml.html"><a href="ml.html#pre-processing"><i class="fa fa-check"></i><b>5.3.1</b> Pre-processing</a></li>
<li class="chapter" data-level="5.3.2" data-path="ml.html"><a href="ml.html#fitting-the-model"><i class="fa fa-check"></i><b>5.3.2</b> Fitting the Model</a></li>
<li class="chapter" data-level="5.3.3" data-path="ml.html"><a href="ml.html#variation-by-comment-score"><i class="fa fa-check"></i><b>5.3.3</b> Variation by Comment Score</a></li>
<li class="chapter" data-level="5.3.4" data-path="ml.html"><a href="ml.html#extending-machine-learning"><i class="fa fa-check"></i><b>5.3.4</b> Extending Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methodsethics.html"><a href="methodsethics.html"><i class="fa fa-check"></i><b>6</b> Further Applications &amp; Ethical Considerations</a>
<ul>
<li class="chapter" data-level="6.1" data-path="methodsethics.html"><a href="methodsethics.html#embeddings"><i class="fa fa-check"></i><b>6.1</b> Embeddings</a></li>
<li class="chapter" data-level="6.2" data-path="methodsethics.html"><a href="methodsethics.html#supervised-classification"><i class="fa fa-check"></i><b>6.2</b> Supervised Classification</a></li>
<li class="chapter" data-level="6.3" data-path="methodsethics.html"><a href="methodsethics.html#networks"><i class="fa fa-check"></i><b>6.3</b> Networks</a></li>
<li class="chapter" data-level="6.4" data-path="methodsethics.html"><a href="methodsethics.html#causality"><i class="fa fa-check"></i><b>6.4</b> Causality</a></li>
<li class="chapter" data-level="6.5" data-path="methodsethics.html"><a href="methodsethics.html#ethics-of-nlp"><i class="fa fa-check"></i><b>6.5</b> Ethics of NLP</a></li>
<li class="chapter" data-level="6.6" data-path="methodsethics.html"><a href="methodsethics.html#future-directions"><i class="fa fa-check"></i><b>6.6</b> Future Directions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a>
<ul>
<li class="chapter" data-level="7.1" data-path="references.html"><a href="references.html#chapter-1--introduction"><i class="fa fa-check"></i><b>7.1</b> Chapter 1- Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="references.html"><a href="references.html#data-and-the-information-age"><i class="fa fa-check"></i><b>7.1.1</b> Data and the Information Age</a></li>
<li class="chapter" data-level="7.1.2" data-path="references.html"><a href="references.html#css-and-nlp"><i class="fa fa-check"></i><b>7.1.2</b> CSS and NLP</a></li>
<li class="chapter" data-level="7.1.3" data-path="references.html"><a href="references.html#nlp-resources-specific-to-r-applications"><i class="fa fa-check"></i><b>7.1.3</b> NLP Resources Specific to R Applications</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="references.html"><a href="references.html#chapter-2--text-preprocessing"><i class="fa fa-check"></i><b>7.2</b> Chapter 2- Text Preprocessing</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="references.html"><a href="references.html#text-preprocessing"><i class="fa fa-check"></i><b>7.2.1</b> Text Preprocessing</a></li>
<li class="chapter" data-level="7.2.2" data-path="references.html"><a href="references.html#stemming-stopwords-and-parts-of-speech"><i class="fa fa-check"></i><b>7.2.2</b> Stemming, Stopwords, and Parts of Speech</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="references.html"><a href="references.html#chapter-3-dictionaries-sentiment-analysis"><i class="fa fa-check"></i><b>7.3</b> Chapter 3 â Dictionaries &amp; Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="references.html"><a href="references.html#counts-dictionary-based-studies"><i class="fa fa-check"></i><b>7.3.1</b> Counts &amp; Dictionary Based Studies</a></li>
<li class="chapter" data-level="7.3.2" data-path="references.html"><a href="references.html#liwc"><i class="fa fa-check"></i><b>7.3.2</b> LIWC</a></li>
<li class="chapter" data-level="7.3.3" data-path="references.html"><a href="references.html#sentiment-analysis-1"><i class="fa fa-check"></i><b>7.3.3</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="7.3.4" data-path="references.html"><a href="references.html#vader-1"><i class="fa fa-check"></i><b>7.3.4</b> VADER</a></li>
<li class="chapter" data-level="7.3.5" data-path="references.html"><a href="references.html#alternative-sentiment-analysis-approaches"><i class="fa fa-check"></i><b>7.3.5</b> Alternative Sentiment Analysis Approaches</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="references.html"><a href="references.html#chapter-4--machine-learning-topic-models"><i class="fa fa-check"></i><b>7.4</b> Chapter 4- Machine Learning &amp; Topic Models</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="references.html"><a href="references.html#machine-learning-for-social-science-annual-reviews"><i class="fa fa-check"></i><b>7.4.1</b> Machine Learning for Social Science Annual Reviews</a></li>
<li class="chapter" data-level="7.4.2" data-path="references.html"><a href="references.html#topic-model-papers"><i class="fa fa-check"></i><b>7.4.2</b> Topic Model Papers</a></li>
<li class="chapter" data-level="7.4.3" data-path="references.html"><a href="references.html#structural-topic-models-author-papers"><i class="fa fa-check"></i><b>7.4.3</b> Structural Topic Models Author Papers</a></li>
<li class="chapter" data-level="7.4.4" data-path="references.html"><a href="references.html#css-research-using-topic-models"><i class="fa fa-check"></i><b>7.4.4</b> CSS Research Using Topic Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="references.html"><a href="references.html#chapter-5--further-applications-ethics"><i class="fa fa-check"></i><b>7.5</b> Chapter 5- Further Applications &amp; Ethics</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="references.html"><a href="references.html#further-applications"><i class="fa fa-check"></i><b>7.5.1</b> Further Applications</a></li>
<li class="chapter" data-level="7.5.2" data-path="references.html"><a href="references.html#ethics-within-nlp"><i class="fa fa-check"></i><b>7.5.2</b> Ethics within NLP</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a>Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Summarise Tables</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> References</h1>
<p>This reference list is divided by each of the user guideâs chapters along with subheaders for the connecting theme between each group of citations. I decided to order each cluster descending by year since NLP is a rapidly growing discipline and starting with older works will likely aid readerâs understanding of newer innovations. The featured references undeniably reflect my own disciplinary training biases in sociology &amp; information science, but I think social scientists outside of either of those specific disciplines can still gain much from the included papers.</p>
<p>I purposely tried to highlight Cornell scholars and researchers throughout the sections. Thereâs no way I could include the sheer variety of research without this list becoming massive, so consider this to be a further reading âlaunch padâ aligned with the introduced topics in the user guide that you can then expand on further within your own literature reviews.</p>
<div id="chapter-1--introduction" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Chapter 1- Introduction</h2>
<div id="data-and-the-information-age" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Data and the Information Age</h3>
<ul>
<li>Golder, Scott and Michael Macy. 2014. âDigital Footprints: Opportunities and Challenges for Online Social Research.â <em>Annual Review of Sociology</em> 40: 129-152.</li>
<li>Salganik, Matthew. 2018. <em>Bit by Bit: Social Research in the Digital Age.</em> Princeton, NJ: Princeton University Press.</li>
<li>Brady, Henry E. 2019. âThe Challenges of Big Data and Data Science.â <em>Annual Review of Political Science</em> 22: 297-323.</li>
<li>Hargittai, Eszter. 2020. âPotential Biases in Big Data: Omitted Voices on Social Media.â <em>Social Science Computer Review</em> 38(1): 10-24.</li>
</ul>
</div>
<div id="css-and-nlp" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> CSS and NLP</h3>
<ul>
<li>DiMaggio, Paul. 2015. âAdapting Computational Text Analysis to Social Science (and Vice Versa).â <em>Big Data &amp; Society</em> 2(2): 1-5.</li>
<li>Evans, James A. and Pedro Aceves. 2016. âMachine Translation: Mining Text for Social Theory.â <em>Annual Review of Sociology</em> 42: 21-50.</li>
<li>Nelson, Laura K. 2017. âComputational Grounded Theory: A Methodological Framework.â <em>Sociological Methods &amp; Research</em> 49(1): 3-42.</li>
<li>Wallach, Hanna. 2018. âComputational Social Science â  Computer Science + Social Data.â <em>Communications of the ACM</em> 61(3): 42-44.</li>
<li>Lazer et al.Â 2020. âComputational Social Science: Obstacles and Opportunities.â <em>Science</em> 369(6507): 1060-1062.</li>
<li>Grimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2021. <em>Text as Data: A New Framework for Machine Learning and the Social Sciences.</em> Princeton, NJ: Princeton University Press.</li>
</ul>
</div>
<div id="nlp-resources-specific-to-r-applications" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> NLP Resources Specific to R Applications</h3>
<ul>
<li>Silge, Julia, and David Robinson. 2017. <em>Text Mining with R: A Tidy Approach.</em> Newton, MA: OâReilly Media</li>
<li>Jockers, Matthew L. and Rosamond Thalken. 2020. <em>Text Analysis with R</em>. New York, NY: Springer.</li>
<li>Hvitfeldt, Emil and Julia Silge. 2021. <em>Supervised Machine Learning for Text Analysis in R.</em> Boca Raton, Florida: CRC Press.</li>
</ul>
</div>
</div>
<div id="chapter-2--text-preprocessing" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Chapter 2- Text Preprocessing</h2>
<div id="text-preprocessing" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Text Preprocessing</h3>
<ul>
<li>Helpful blog post on encodings- <a href="https://kunststube.net/encoding/" class="uri">https://kunststube.net/encoding/</a></li>
<li>Uysal, A. K., and Gunal, S. 2014. âThe Impact of Preprocessing on Text Classification.â <em>Information Processing &amp; Management</em> 50(1), 104-112.</li>
<li>Denny, M. J., and Spirling, A. 2018. âText Preprocessing For Unsupervised Learning: Why It Matters, When It Misleads, And What To Do About It.â <em>Political Analysis</em> 26(2): 168â189.</li>
<li>Hickman, Louis, Stuti Thapa, â¦ et al.Â 2020. âText Preprocessing for Text Mining in Organizational Research: Review and Recommendations.â <em>Organizational Research Methods</em>: 1-33.</li>
<li>Great website to learn regexes- <a href="https://www.regular-expressions.info/" class="uri">https://www.regular-expressions.info/</a></li>
</ul>
</div>
<div id="stemming-stopwords-and-parts-of-speech" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Stemming, Stopwords, and Parts of Speech</h3>
<ul>
<li>Derczynski, Leon, Alan Ritter, Sam Clark, and Kalina Bontcheva. 2013. âTwitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data.â <em>Proceedings of Recent Advances in Natural Language Processing</em>: 198-206.</li>
<li>Tsuboi, Yuta. 2014. âNeural Networks Leverage Corpus-wide Information for Part-of-Speech Tagging.â <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</em>: 938-950.</li>
<li>Schofield, A., and Mimno, D. 2016. âComparing Apples to Apple: The Effects of Stemmers on Topic Models.â <em>TACL</em> 4(2): 287â300.</li>
<li>Singh, Jasmeet and Vishal Gupta. 2017. âA Systematic Review of Text Stemming Techniques.â <em>Artificial Intelligence Review</em> 48: 157-217.</li>
<li>Schofield, Alexandra, MÃ¥ns Magnusson, and David Mimno. 2017. âPulling Out the Stops: Rethinking Stopword Removal for Topic Models.â <em>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</em>: 432-436.</li>
</ul>
</div>
</div>
<div id="chapter-3-dictionaries-sentiment-analysis" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Chapter 3 â Dictionaries &amp; Sentiment Analysis</h2>
<div id="counts-dictionary-based-studies" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Counts &amp; Dictionary Based Studies</h3>
<ul>
<li>Monroe, Burt, Michael Colaresi, and Kevin Quinn. 2008. âFightinâ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict.â <em>Political Analysis</em> 16(4): 372-403.</li>
<li>Loughran, Tim and Bill McDonald. 2011. âWhen Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ksâ <em>The Journal of Finance</em> 66(1): 35-65.</li>
<li>Sap, Maarten, Marcella Cindy Prasetio, Ari Holtzman, Hannah Rashkin, and Yejin Choi. 2017. âConnotation Frames of Power and Agency in Modern Films.â <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>: 2329-2334.</li>
<li>Antoniak, Maria and David Mimno. 2021. âBad Seeds: Evaluating Lexical Methods for Bias Measurement.â <em>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</em>: 1889-1904.</li>
</ul>
</div>
<div id="liwc" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> LIWC</h3>
<ul>
<li>Tausczik, Yla R., and James W. Pennebaker. 2010. âThe Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods.â <em>Journal of Language and Social Psychology</em> 29(1): 24-54.</li>
<li>Bulkeley, Kelly and Mark Graves. 2018. âUsing the LIWC program to study dreams.â <em>Dreaming</em> 28(1): 43â58.</li>
<li>Sergent, Kayla and Alexander D. Stajkovic. 2020. âWomenâs Leadership is Associated with Fewer Deaths During the COVID-19 Crisis: Quantitative and Qualitative Analyses of United States Governors.â <em>Journal of Applied Psychology</em> 105(8): 771-783.</li>
<li>Yin, Dezhi, Samuel D. Bond, and Han Zhang. 2021. âAnxious or Angry? Effects of Discrete Emotions on the Perceived Helpfulness of Online Reviews.â <em>MIS Quarterly</em> 38(2): 539-560.</li>
</ul>
</div>
<div id="sentiment-analysis-1" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Sentiment Analysis</h3>
<ul>
<li>Pang, Bo, and Lillian Lee. 2008. âOpinion Mining and Sentiment Analysis.â <em>Foundations and Trends in Information Retrieval</em> 2(1â2): 1â135.</li>
<li>Bao, Yanwei, Changqin Qian, Lijuan Wang, and Fuji Ren. 2014. âThe Role of Pre-Processing in Twitter Sentiment Analysis.â <em>International Conference on Intelligent Computing</em>: 615-624.</li>
<li>Chauhan, Priyavrat, Nonita Sharma, and Geeta Sikka. 2021. âThe Emergence of Social Media Data and Sentiment Analysis in Election Prediction.â <em>Journal of Ambient Intelligence and Humanized Computing</em> 12: 2601-2627.</li>
</ul>
</div>
<div id="vader-1" class="section level3" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> VADER</h3>
<ul>
<li>OâConnor, Brendan, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. âFrom Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series.â <em>Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM)</em>: 122-129.</li>
<li>Hutto, C.J. and Eric Gilbert. 2014. âVADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.â <em>Proceedings of the Eighth International AAAI Conference on Weblogs and Social Media</em>: 216-225.</li>
<li>Kim, Young Bin, Jun Gi Kim, â¦ et al.Â 2016. âPredicting Fluctuations in Cryptocurrency Transactions Based on User Comments and Replies.â <em>PLOS ONE</em> 11(8): 1-17.</li>
<li>Kumar, Srijan, William L. Hamilton, Jure Leskovec, and Dan Jurafsky. 2018. âCommunity Interaction and Conflict on the Webâ <em>WWW</em>: 933-943.</li>
</ul>
</div>
<div id="alternative-sentiment-analysis-approaches" class="section level3" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Alternative Sentiment Analysis Approaches</h3>
<ul>
<li>Soleymani, Mohammad, David Garcia, â¦ et al.Â 2017. âA Survey of Multimodal Sentiment Analysis.â <em>Image and Vision Computing</em> 65: 3-14.</li>
<li>Hemmatian, Fatemeh and Mohammad Karim Sohrabi. 2019. âA Survey on Classification Techniques for Opinion Mining and Sentiment Analysis.â <em>Artificial Intelligence Review</em> 52: 1495-1545.</li>
<li>Yadav, Ashima and Dinesh Kumar Vishwakarma. 2019. âSentiment Analysis Using Deep Learning Architectures: A Review.â <em>Artificial Intelligence Review</em> 53: 4335-4385.</li>
</ul>
</div>
</div>
<div id="chapter-4--machine-learning-topic-models" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Chapter 4- Machine Learning &amp; Topic Models</h2>
<div id="machine-learning-for-social-science-annual-reviews" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Machine Learning for Social Science Annual Reviews</h3>
<ul>
<li>Molina, Mario and Filiz Garip. 2019. âMachine Learning for Sociology.â <em>Annual Review of Sociology</em> 45: 27-45.</li>
<li>Athey, Susan and Guido W. Imbens. 2019. âMachine Learning Methods That Economists Should Know About.â <em>Annual Review of Economics</em> 11: 685-725.</li>
<li>OrrÃ¹, Graziella, Merylin Monaro, â¦ et al.Â 2020. âMachine Learning in Psychometrics and Psychological Research.â <em>Frontiers in Psychology</em> 10(2970): 1-10.</li>
<li>Grimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2021. âMachine Learning for Social Science: An Agnostic Approach.â <em>Annual Review of Political Science</em> 24: 395-419.</li>
</ul>
</div>
<div id="topic-model-papers" class="section level3" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Topic Model Papers</h3>
<ul>
<li>Chang, Jonathan, Jordan Boyd-Graber, Sean Gerrish, Chong Wang, and David M. Blei. 2009. âReading Tea Leaves: How Humans Interpret Topic Models.â <em>Advances in Neural Information Processing Systems</em> 22: 1-9.</li>
<li>Blei, David. 2012. âProbabilistic Topic Models.â <em>Communications of the ACM</em> 55 (4): 77-84.</li>
<li>Mohr, John, and Petko Bogdanov. 2013. âIntroductionâTopic Models: What They Are and Why They Matter.â <em>Poetics</em> 41 (6): 545â69.</li>
<li>Baumer, Erin P.S., David Mimno, Shion Guha, Emily Quan, and Geri K. Gay. 2017. âComparing Grounded Theory and Topic Modeling: Extreme Divergence or Unlikely Convergence?â <em>Journal of the Association for Information Science and Technology</em> 68(6): 1397-1410.</li>
</ul>
</div>
<div id="structural-topic-models-author-papers" class="section level3" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Structural Topic Models Author Papers</h3>
<ul>
<li>Check out the structural topic model website for an extensive list of studies that have used STMs - <a href="https://www.structuraltopicmodel.com/" class="uri">https://www.structuraltopicmodel.com/</a></li>
<li>Roberts, Stewart, Tingley, Lucas, Leder-Luis, Gadarian, Albertson, and Rand. 2014. âStructural Topic Models for Open-Ended Survey Responses.â <em>American Journal of Political Science</em> 58(4): 1064-1082.</li>
<li>Roberts, Margaret, Brandon Stewart, and Dustin Tingley. 2019. âstm: A Package for Structural Topic Models.â <em>Journal of Statistical Software</em> 91(2):1-40.</li>
</ul>
</div>
<div id="css-research-using-topic-models" class="section level3" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> CSS Research Using Topic Models</h3>
<ul>
<li>DiMaggio, Paul, Manish Nag, and David Blei. 2013. âExploiting Affinities between Topic Modeling and the Sociological Perspective on Culture: Application to Newspaper Coverage of U.S. Government Arts Funding.â <em>Poetics</em> 41(6): 570-606.</li>
<li>BarberÃ¡, Pablo, Andreu Casas, Jonathan Nagler, Patrick J. Egan, Richard Bonneau, John T. Jost, and Joshua A. Tucker. 2019. âWho Leads? Who Follows? Measuring Issue Attention and Agenda Setting by Legislators and the Mass Public Using Social Media Data.â <em>American Political Science Review</em> 113(4): 883-901.</li>
<li>Karell, Daniel and Michael Freedman. 2019. âRhetorics of Radicalism.â <em>American Sociological Review</em> 84(4): 726-753.<br />
</li>
<li>Kennedy, I., C. Hess, A. Paullada, and S. Chasins. 2021. âRacialized Discourse in Seattle Rental Ad Text.â <em>Social Forces</em> 99(4): 1432â1456.</li>
</ul>
</div>
</div>
<div id="chapter-5--further-applications-ethics" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Chapter 5- Further Applications &amp; Ethics</h2>
<div id="further-applications" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Further Applications</h3>
<div id="word-embeddings" class="section level4" number="7.5.1.1">
<h4><span class="header-section-number">7.5.1.1</span> Word Embeddings</h4>
<ul>
<li>Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. âEfficient Estimation of Word Representations in Vector Space.â <em>Proceedings of Workshop at ICLR</em>: 1-22.</li>
<li>Levy, Omer and Yoav Goldberg. 2014. âNeural Word Embedding as Implicit Matrix Factorization.â <em>Advances in Neural Information Processing Systems</em> 27: 1-9.</li>
<li>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. âWord Embeddings Quantify 100 years of Gender and Ethnic Stereotypes.â <em>Proceedings of the National Academy of Sciences</em> 115(16): E3635âE3644.</li>
<li>Kozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. âThe Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.â <em>American Sociological Review</em> 84(5): 905â949.</li>
<li>Arseniev-Koehler, Alina and Jacob G. Foster. 2020. âMachine Learning as a Model for Cultural Learning: Teaching an Algorithm what it Means to be Fat.â Preprint, SocArXiv.</li>
</ul>
</div>
<div id="supervised-nlp-classification-applied-studies" class="section level4" number="7.5.1.2">
<h4><span class="header-section-number">7.5.1.2</span> Supervised NLP Classification Applied Studies</h4>
<ul>
<li>Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, and Lillian Lee. 2016. âWinning Arguments: Interaction Dynamics and Persuasion Strategies in Good-Faith Online Discussions,â <em>WWW</em>: 613â624.</li>
<li>Davidson, Thomas, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. âAutomated Hate Speech Detection and the Problem of Offensive Language.â <em>Proceedings of the 11th International Conference on Web and Social Media (ICWSM)</em>: 512â515.</li>
<li>Zhang, Justine, Jonathan P. Chang, Christian Danescu-Niculescu-Mizil, Lucas Dixon, Nithum Thain, Yiqing Hua, and Dario Taraborelli. 2018. âConversations Gone Awry: Detecting Early Signs of Conversational Failure.â <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</em> 1: 1350-1361.</li>
<li>BarberÃ¡, Pablo, Amber E. Boydstun, Suzanna Linn, Ryan McMahon, and Jonathan Nagler. 2020. âAutomated Text Classification of News Articles: A Practical Guide.â <em>Political Analysis</em>: 1â24</li>
</ul>
</div>
<div id="networks-1" class="section level4" number="7.5.1.3">
<h4><span class="header-section-number">7.5.1.3</span> Networks</h4>
<ul>
<li>Gonzales-Bailon, Sanda, Andreas Kaltenbrunner, and Rafael E Banchs. 2010. âThe Structure of Political Discussion Networks: A Model for the Analysis of Online Deliberation.â <em>Journal of Information Technology</em> 25: 230-243.</li>
<li>Rule, Alix, Jean-Phillippe Cointet, and Peter S. Bearman. 2015. âLexical Shifts, Substantive Changes, and Continuity in State of the Union Discourse, 1790-2014.â <em>PNAS</em> 112(35): 10837-10844.</li>
<li>Bail, Christopher A. 2016. âCombining Natural Language Processing and Network Analysis to Examine How Advocacy Organizations Stimulate Conversation on Social Media.â <em>Proceedings of the National Academy of Sciences</em> 113(42): 11823-28.</li>
<li>Vega, Davide and Matteo Magnani. 2018. âFoundations of Temporal Text Networks.â <em>Applied Network Science</em> 3(25): 1-26.</li>
</ul>
</div>
<div id="casual-inference" class="section level4" number="7.5.1.4">
<h4><span class="header-section-number">7.5.1.4</span> Casual Inference</h4>
<ul>
<li>Great GitHub repository of text &amp; causality papers across disciplines-<a href="https://github.com/causaltext/causal-text-papers" class="uri">https://github.com/causaltext/causal-text-papers</a></li>
<li>Bryan, Christopher J., Gregory M. Walton, Todd Rogers, and Carol S. Dweck. 2011. âMotivating Voter Turnout by Invoking the Self.â <em>PNAS</em> 108(31): 12653-12656.</li>
<li>Feder et al.Â 2021. âCausal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond.â arXiv preprint arXiv: 2109.00725.</li>
<li>Pryzant, Reid, Dallas Card, Dan Jurafsky, Victor Veitch, and Dhanya Sridhar. 2021. âCausal Effects of Linguistic Properties.â <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>: 4095-4109.</li>
</ul>
</div>
</div>
<div id="ethics-within-nlp" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Ethics within NLP</h3>
<p>Hereâs a fantastic fairness within NLP Github repo from the UCLA NLP group that the following citations also draws from- <a href="https://github.com/uclanlp/awesome-fairness-papers" class="uri">https://github.com/uclanlp/awesome-fairness-papers</a></p>
<div id="broad-social-implications-of-nlp" class="section level4" number="7.5.2.1">
<h4><span class="header-section-number">7.5.2.1</span> Broad Social Implications of NLP</h4>
<ul>
<li>Hovy, Dirk and Shannon L. Spruit. 2016. âThe Social Impact of Natural Language Processing.â <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</em> 2: 591-598.</li>
<li>Blodgett, Su Lin, Solon Barocas, Hal Daum III, and Hanna Wallach. 2020. âLanguage (Technology) is Power: A Critical Survey of âBiasâ in NLP.â <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5454-5476.</li>
<li>Leins, Kobi, Jey Han Lau, and Timothy Baldwin. 2020. âGive Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?â <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 2908-2913.</li>
</ul>
</div>
<div id="nlps-perpetuation-of-bias-and-unethical-practices" class="section level4" number="7.5.2.2">
<h4><span class="header-section-number">7.5.2.2</span> NLPâs Perpetuation of Bias and Unethical Practices</h4>
<ul>
<li>Sap, Maarten, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. 2019. âThe Risk of Racial Bias in Hate Speech Detection.â <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 1668-1678.</li>
<li>Gonen, Hila and Yoav Goldberg. 2019. âLipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But Do Not Remove Them.â <em>Proceedings of NAACL-HLT</em>: 609-614.</li>
<li>Hutchinson, Ben, Vinodkumar Prabhakaran, â¦ et al.Â 2020. âSocial Biases in NLP Models as Barriers for Persons with Disabilities.â <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5491-5501.</li>
<li>Shmueli, Boaz, Jan Fell, Soumya Ray, and Lun-Wei Ku. 2021. âBeyond Fair Pay: Ethical Implications of NLP Crowdsourcingâ <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>: 3758â3769</li>
<li>Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Smitchell. 2021. âOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?â <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>: 610-623.</li>
</ul>
</div>
<div id="nlps-revealing-of-bias-and-unethical-practices" class="section level4" number="7.5.2.3">
<h4><span class="header-section-number">7.5.2.3</span> NLPâs Revealing of Bias and Unethical Practices</h4>
<ul>
<li>Voigt, Rob, Nicholas P Camp, â¦ et al.Â 2017. âLanguage from Police Body Camera Footage Shows Racial Disparities in Officer Respect.â <em>PNAS</em> 114(25): 6521-6526.</li>
<li>Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. âWord embeddings quantify 100 years of gender and ethnic stereotypes.â <em>Proceedings of the National Academy of Sciences 115</em> (16): E3635âE3644.</li>
<li>Merullo, Jack, Luke Yeh, â¦ et al.Â 2019. âInvestigating Sports Commentator Bias Within a Large Corpus of American Football Broadcasts.â <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</em>: 6355-6361.</li>
<li>Sap, Maarten, Saadia Gabriel, â¦ et al.Â 2020. âSocial Bias Frames: Reasoning about Social and Power Implications of Language.â <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>: 5477-5490.</li>
</ul>
</div>
<div id="participant-privacy-consent-and-agency" class="section level4" number="7.5.2.4">
<h4><span class="header-section-number">7.5.2.4</span> Participant Privacy, Consent, and Agency</h4>
<ul>
<li>Nissenbaum, Helen. 2004. âPrivacy as Contextual Integrity.â <em>Washington Law Review</em> 79(1): 101-139.</li>
<li>Williams, Matthew L., Pete Burnap, and Luke Sloan. 2017. âTowards an Ethical Framework for Publishing Twitter Data in Social Research: Taking into Account Usersâ Views, Online Context and Algorithmic Estimation.â <em>Sociology</em> 51(6): 1149-1168.</li>
<li>Susser, Daniel, Beate Roessler, and Helen Nissenbaum. 2019. âTechnology, Autonomy, and Manipulation.â <em>Internet Policy Review</em> 8(2): 1-22.</li>
<li>Caselli, Tommaso, Roberto Cibin, â¦ et al.Â 2021. âGuiding Principles for Participatory Design-Inspired Natural Language Processing.â <em>Proceedings of the 1st Workshop on NLP for Positive Impact</em>: 27-35.</li>
</ul>
</div>
<div id="incorporating-ethical-practices-within-nlp" class="section level4" number="7.5.2.5">
<h4><span class="header-section-number">7.5.2.5</span> Incorporating Ethical Practices Within NLP</h4>
<ul>
<li>Bender, Emily M. and Batya Friedman. 2018. âData Statements for Natural Language Processing: Towards Mitigating System Bias and Enabling Better Science.â <em>Transactions of the Association for Computational Linguistics</em> 6: 587-604.</li>
<li>Jurgens, David, Eshwar Chandrasekharan, and Libby Hemphill. 2019. âA Just and Comprehensive Strategy for Using NLP to Address Online Abuse.â <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 3658-3666.</li>
<li>Sun, Tony, Andrew Gautâ¦ et al.Â 2019. âMitigating Gender Bias in Natural Language Processing: Literature Review.â <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>: 1630-1640.</li>
<li>Havens, Lucy, Melissa Terras, Benjamin Bach, and Beatrice Alex. 2020. âSituated Data, Situated Systems: A Methodology to Engage with Power Relations in Natural Language Processing Research.â <em>Proceedings of the Second Workshop on Gender Bias in Natural Language Processing</em>: 107-124.</li>
</ul>

<p>In this demo, weâll be performing exploratory analysis on the expressed emotional
sentiment of r/nyc users as embedded within their comment text. We will use readr,
dplylr, and stringr once again as these packages are core libraries
across NLP use cases. Weâre also including the <strong>vader</strong> package which wraps the original
VADER sentiment analyser written in Python for R as well as <strong>ggplot</strong> for simple
data visualizations. Letâs load them all in along with our r/nyc comment data set as follows:</p>
<p>library(readr)
library(dplyr)
library(stringr)
library(vader)
library(ggplot2)</p>
<p>nyc &lt;- read_csv(ânyc_reddit.csvâ)</p>
<p>get_vader(âAs someone who always depended on cars before, I LOVE the subway! &lt;3â)</p>
<p>get_vader(âThe subway is very helpful, but Iâm not a fan of the rats.â)</p>
<p>get_vader(âI hate how delayed the subway always isâ¦ being late for work sucks. :(â)</p>
<p>nyc_sentiment &lt;- vader_df(nyc$body)
nyc_sentiment</p>
<p>nyc_sentiment &lt;- read_csv(ânyc_sentiment.csvâ)</p>
<p>top_pos &lt;- nyc_sentiment %&gt;%
top_n(5, compound)
top_pos$body</p>
<p>top_neg &lt;- nyc_sentiment %&gt;%
top_n(-5, compound)
top_neg</p>
<p>nyc_full &lt;- merge(nyc, nyc_sentiment, by = âbodyâ)</p>
<p>To prepare for this analysis, Iâll first have to join my separate data frames of
both the baseline Reddit data and the VADER scores by comment. Weâll then consider
comments with a positive rating score of 20 through ggplot scatter plots.</p>
<p>ggplot(nyc_full[which(nyc_full$score&gt;20),], aes(x=compound, y=score)) + geom_point()</p>
<p>Letâs look at the equivalent for sentiment among posts that received a negative score.</p>
<p>ggplot(nyc_full[which(nyc_full$score&lt;0),], aes(x=compound, y=score)) + geom_point()</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methodsethics.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-references.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
